---
title: "modelo econometrico"
author: "Ana Munoz"
date: "2024-02-15"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE}
# LIBRERIA USADAS
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(corrplot)
library(psych)
library(ggplot2)
library(fitdistrplus)
library(plm)
library(lmtest)
```

# Pre procesamiento de datos
## 1. Lectura de datos y formato panel

```{r}
df <- read.csv('df_17_21.csv') %>%
  dplyr::select(year, country, total_earnings, # orden de datos panel
         -total_players, -iso, #no aplica el modelo
         gdp_gr, -GNI_cap, -pbicap, -poder_adq, # las engloba pbippa
         pbippa, # variables macroeconomicas
         gastoedu, # edu
         CPI, # corrupcion
         desempleo,# work
         desnutricion, # pobreza
         internet, elect_acc, movil, # tech access
         age_game, # edades
         poblacion, pop_growth, rural_per# people
        ) %>%
  arrange(country, decreasing = FALSE)

head(df, 3)
```

## 2.  Valores faltantes
* Numero de Valores faltantes por variable
```{r}
sapply(df, function(x) sum(is.na(x)))
```
* corriegiendo los NAs
```{r}
# Internet: 2 faltantes -> 2018 cambodia y trinidad y tobago

### Cambodia, hueco en 2018, reemplazdo por el promedio

df[df$country=='Cambodia', 'internet'][2] <- 
          (df[df$country=='Cambodia', 'internet'][1] + 
             df[df$country=='Cambodia', 'internet'][3])/2

### trinidad y tobago, reemplazdo por el promedio
df[df$country=='Trinidad and Tobago', 'internet'][2] <- 
          (df[df$country=='Trinidad and Tobago', 'internet'][1]+
              df[df$country=='Trinidad and Tobago', 'internet'][3])/2

# gasto en educacion

### para continuar con el analisis sin NAs, elimnare esta varible temporal
df <- df%>%dplyr::select(-gastoedu)

# verificamos NAs, ahora no tengo NAS
sapply(df, function(x) sum(is.na(x)))
```
## 3.  Normalizacion con logaritmo

* valores con varianzas muy grandes

```{r}
summary(df)
```
* aplico normalizacion logaritmica en algunas variables
```{r}
df_standar <- df %>% 
  mutate(across(c("total_earnings", "pbippa", "poblacion"), ~log(.) %>% as.vector))
```

## 4. Correlacion y eliminacion de variables
* verificacion de correlaciones
```{r}
matriz_corr <- cor(df_standar[3:15])
corrplot(matriz_corr, method = 'number', number.cex = 0.7) 
```

* Veamos mas a detalle las correlaciones encontradas,  pbippa,  cpi e acceso internet
 Se debe crear otra variable para eliminar la correlacion?
 estas correlaciones no implican causalidad, pero como debo tratarlas?
```{r}
pairs.panels(df_standar%>%dplyr::select(total_earnings,pbippa, internet,CPI),
             smooth = FALSE,     # Si TRUE, dibuja ajuste suavizados de tipo loess
             scale = FALSE,      # Si TRUE, escala la fuente al grado de correlación
             density = TRUE,     # Si TRUE, añade histogramas y curvas de densidad
             ellipses = FALSE,   # Si TRUE, dibuja elipses
             method = "pearson", # Método de correlación (también "spearman" o "kendall")
             lm = TRUE,          # Si TRUE, dibuja un ajuste lineal en lugar de un ajuste LOESS
             cor = TRUE,         # Si TRUE, agrega correlaciones
             jiggle = FALSE,     # Si TRUE, se añade ruido a los dato
) 

```

## 5. Distribucion de los datos

* Al parecer, cada year las ganacias se estan concentrando como una distribucionlognormal

```{r}
ggplot(df_standar, aes(x = total_earnings)) +
  geom_density(color = "skyblue", linewidth = 0.5) +
  facet_wrap(~ year, ncol = 3) +
  labs(title = "Densidad de Total Earnings por Año",
       x = "Total Earnings",
       y = "Densidad") +
  theme_minimal()
```
* conociendo las distribuciones de los ingrsos por ano
```{r}
# df_year <- df_standar%>%filter(year=='2020-01-01') 
# descdist(df_year$total_earnings)
```
* un test de shapiro para comprobar y vemos que solo el 2019 no tendria una distribucion normal
```{r}

years <- c('2017-01-01','2018-01-01','2019-01-01','2020-01-01','2021-01-01')
resultados <- data.frame(year = character(0), p_value = numeric(0))
for (i in years) {
  df_year <- df_standar %>% filter(year == i)
  p_value <- shapiro.test(df_year$total_earnings)$p.value
  resultados <- rbind(resultados, data.frame(year = i, p_value = p_value))
}
print(resultados)
  
```


# Implementando modelos

## 0. Preparando los datos
* tenemos datos panel con la siguente forma 90 paises 5 anios y estas cols
```{r}
# df_panel <- df_standar # por si sera necesario quitar algunas var
dim(table(df_standar$country,df_standar$year))

colnames(df_standar)
```

* definimos las variables para el modelo
```{r, warning=FALSE}
attach(df_standar)
Y <- cbind(total_earnings)
X <- cbind(gdp_gr, pbippa, CPI, desempleo, desnutricion, internet,
           elect_acc, movil, age_game, poblacion, pop_growth, rural_per)

df_panel <- pdata.frame(df_standar, index=c('country','year'))

head(df_panel,3)
```

## 1. Pooled OLS estimator
```{r}
pooling <- plm(Y ~ X, data=df_panel, model= "pooling")
summary(pooling)
```

## 2. Between estimator
```{r}
between <- plm(Y ~ X, data=df_panel, model= "between")
summary(between)
```

## 3. First differences estimator
```{r}
firstdiff <- plm(Y ~ X, data=df_panel, model= "fd")
summary(firstdiff)
```

## 4. Fixed effects or within estimator
```{r}
fixed <- plm(Y ~ X, data=df_panel, model= "within")
summary(fixed)
```

## 5. Random effects estimator
```{r}
random <- plm(Y ~ X, data=df_panel, model= "random")
summary(random)
```


# Test

## LM test for random effects versus OLS
* H0 = los efectos aleatorios no son significativos no soportan el modelo (p rechazo)
* H1 = los efectos aleatorios sí son significativos
* los efectos aleatorios son importantes y deben considerarse en el modelo.
* OLS no captura completamente la variabilidad debida a los efectos aleatorios

```{r}
plmtest(pooling)
```

## LM test for fixed effects versus OLS
* H0 = los efectos fijos no son significativos no soportan el modelo (p rechazo)
* los efectos fijos son importantes y deben considerarse en el modelo.
* OLS no captura completamente la variabilidad debida a los efectos fijos

```{r}
pFtest(fixed, pooling)
```

## Hausman test for fixed versus random effects model
* hipótesis alternativa es que uno de los modelos es inconsistente.
* p es 0.0001451 rechazo la hipótesis nula
*  uno de los modelos es inconsistente.
```{r}
phtest(random, fixed)
```
## Cluster standar error

* Para los efectos fijos
```{r}
coeftest(fixed, vcovHC(fixed, type='HC0', cluster='group'))
```

# Modificaciones el modelo elegido

# Cambios en el nuevo modelo
```{r}
X_2 <- cbind(gdp_gr, desempleo, 
             # desnutricion,
             internet,
           elect_acc, age_game, poblacion, rural_per)


fixed_2 <- plm(Y ~ X_2, data=df_panel, model= "within")
summary(fixed_2)
```

```{r}
coeftest(fixed_2, vcovHC(fixed_2, type='HC0', cluster='group'))
```


